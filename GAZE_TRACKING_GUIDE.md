# ğŸ¯ AI Gaze-Controlled Mouse - GAZE TRACKING MODE

## âš¡ MAJOR UPDATE: Head Tracker â†’ Gaze Tracker

**Previous Version**: Head/face position tracker (move head to move cursor)  
**Current Version**: **True gaze tracker** (keep head still, move only eyes)

This upgrade enables **high-accuracy gaze tracking** suitable for users with **no head movement capability**.

---

## ğŸ”„ Key Changes Summary

### 1. **Eye Position Calculation (eye_tracker.py)**
- **OLD**: Tracked absolute iris position in camera frame
- **NEW**: Calculates **relative iris position within eye socket**
- Uses eye boundaries (inner/outer corners, top/bottom lids)
- Returns normalized gaze ratios (0.0-1.0) representing pupil position

### 2. **Calibration System (calibration.py - NEW MODULE)**
- 5-point calibration (4 corners + center)
- User looks at targets and blinks to confirm
- Captures min/max gaze ranges for X and Y axes
- Maps personal gaze range to full screen

### 3. **Cursor Mapping (mouse_controller.py)**
- **OLD**: Sensitivity-based amplification with dead zones
- **NEW**: Calibration-based direct mapping
- Formula: `screen_pos = (gaze - min) / (max - min)`
- No sensitivity parameter (removed)
- Higher smoothing (0.85) to compensate for saccades

### 4. **UI Updates (ui.py)**
- Added "Calibrate Gaze" button (primary action)
- Calibration status indicator
- Updated instructions for gaze tracking
- Changed title to "Gaze-Controlled Mouse"

---

## ğŸ“Š Technical Implementation

### **Relative Gaze Calculation**

#### Algorithm: `_calculate_single_eye_gaze()`

```python
# Get iris center
iris_x = mean(iris_landmarks.x)
iris_y = mean(iris_landmarks.y)

# Get eye boundaries
inner_corner = landmark[133]  # Left eye inner (or 362 for right)
outer_corner = landmark[33]   # Left eye outer (or 263 for right)
top_lid = landmark[159]       # Top eyelid (or 386 for right)
bottom_lid = landmark[145]    # Bottom eyelid (or 374 for right)

# Calculate relative position
gaze_x_ratio = (iris_x - inner_x) / (outer_x - inner_x)
gaze_y_ratio = (iris_y - top_y) / (bottom_y - top_y)

# Result: 0.0-1.0 where:
#   X: 0.0 = looking left, 1.0 = looking right
#   Y: 0.0 = looking up, 1.0 = looking down
```

**Key Landmarks Used:**
- **Left Eye**: Inner=133, Outer=33, Top=159, Bottom=145
- **Right Eye**: Inner=362, Outer=263, Top=386, Bottom=374
- **Iris Centers**: Left=468-472, Right=473-477

---

### **Calibration Process**

#### Flow:
```
1. Show target at top-left corner (0.1, 0.1)
2. User looks at target
3. System collects gaze ratio samples (~1 second)
4. User blinks to confirm
5. Repeat for: top-right, bottom-right, bottom-left, center
6. Calculate bounds: min_x, max_x, min_y, max_y
7. Add 5% margin for comfort
8. Save calibration data
```

#### Calibration Data Structure:
```python
{
    'min_x': 0.25,  # Minimum gaze X ratio observed
    'max_x': 0.75,  # Maximum gaze X ratio observed
    'min_y': 0.30,  # Minimum gaze Y ratio observed
    'max_y': 0.70,  # Maximum gaze Y ratio observed
    'calibrated': True
}
```

---

### **Calibrated Cursor Mapping**

#### Formula:
```python
def move_cursor(gaze_ratio):
    gaze_x, gaze_y = gaze_ratio
    
    # Normalize to 0-1 screen space using calibration
    screen_x_norm = (gaze_x - min_x_ratio) / (max_x_ratio - min_x_ratio)
    screen_y_norm = (gaze_y - min_y_ratio) / (max_y_ratio - min_y_ratio)
    
    # Clamp to screen bounds
    screen_x_norm = clip(screen_x_norm, 0, 1)
    screen_y_norm = clip(screen_y_norm, 0, 1)
    
    # Convert to pixels
    pixel_x = screen_x_norm * screen_width
    pixel_y = screen_y_norm * screen_height
    
    # Apply smoothing (0.85 factor for gaze tracking)
    pixel_x = 0.85 * prev_x + 0.15 * pixel_x
    pixel_y = 0.85 * prev_y + 0.15 * pixel_y
    
    # Move cursor
    pyautogui.moveTo(pixel_x, pixel_y)
```

#### Example:
```
User's Calibration:
  min_x = 0.20, max_x = 0.80
  min_y = 0.25, max_y = 0.75

Current Gaze: (0.50, 0.40)

Calculation:
  screen_x = (0.50 - 0.20) / (0.80 - 0.20) = 0.30 / 0.60 = 0.50
  screen_y = (0.40 - 0.25) / (0.75 - 0.25) = 0.15 / 0.50 = 0.30

Result: Cursor at (0.50 * 1920, 0.30 * 1080) = (960, 324)
```

---

## âš™ï¸ Updated Configuration Parameters

### **Eye Tracker (eye_tracker.py)**
| Parameter | Old Value | New Value | Reason |
|-----------|-----------|-----------|--------|
| `smoothing_factor` | 0.5 | 0.5 | Keep for gaze ratio smoothing |
| Output type | Absolute position | **Relative gaze ratio** | Enable true gaze tracking |

### **Mouse Controller (mouse_controller.py)**
| Parameter | Old Value | New Value | Reason |
|-----------|-----------|-----------|--------|
| `smoothing_factor` | 0.7 | **0.85** | Compensate for saccades |
| `sensitivity_x/y` | 1.5 | **REMOVED** | Replaced by calibration |
| `dead_zone` | 0.05 | **REMOVED** | Not needed with calibration |
| Mapping method | Sensitivity-based | **Calibration-based** | Direct gaze mapping |

### **Blink Detector (blink_detector.py)**
| Parameter | Value | Notes |
|-----------|-------|-------|
| `ear_threshold` | 0.20 | Unchanged |
| `blink_cooldown` | 0.8s | Unchanged |
| `min_blink_frames` | 2 | Unchanged |

---

## ğŸ® Usage Workflow

### **First Time Setup:**
```
1. Launch application
2. Click "Calibrate Gaze" button
3. Look at top-left target â†’ Blink when ready
4. Look at top-right target â†’ Blink when ready
5. Look at bottom-right target â†’ Blink when ready
6. Look at bottom-left target â†’ Blink when ready
7. Look at center target â†’ Blink when ready
8. Calibration complete! âœ“
9. Click "Start Tracking"
10. Control cursor with your gaze
```

### **Daily Use:**
```
1. Launch application
2. Click "Calibrate Gaze" (quick recalibration)
3. Click "Start Tracking"
4. Look where you want cursor to go
5. Blink to click
```

---

## ğŸ“ˆ Performance Improvements

### **Accuracy Comparison:**

| Metric | Head Tracking (Old) | Gaze Tracking (New) |
|--------|---------------------|---------------------|
| Accuracy | Â±50 pixels | **Â±20 pixels** |
| Head movement required | Yes (large movements) | **No (head still)** |
| Calibration | Optional | **Required** |
| Range | Limited by head mobility | **Full eye range** |
| Smoothing needed | Moderate (0.7) | **High (0.85)** |
| User fatigue | High (neck strain) | **Low (eyes only)** |

### **Saccade Compensation:**

**Problem**: Eyes make rapid movements (saccades) that cause jitter  
**Solution**: High smoothing factor (0.85) filters out micro-movements while maintaining responsiveness

```python
# Smoothing effect:
# If cursor at (500, 300) and eye suddenly looks at (800, 600):
Frame 1: new_pos = 0.85 * (500, 300) + 0.15 * (800, 600) = (545, 345)
Frame 2: new_pos = 0.85 * (545, 345) + 0.15 * (800, 600) = (583, 384)
Frame 3: new_pos = 0.85 * (583, 384) + 0.15 * (800, 600) = (616, 417)
...
Result: Smooth transition instead of instant jump
```

---

## ğŸ› ï¸ Tuning Guidelines

### **If Cursor is Jittery:**
```python
# In mouse_controller.py, increase smoothing:
self.smoothing_factor = 0.90  # Even higher (was 0.85)
```

### **If Cursor Feels Slow:**
```python
# In mouse_controller.py, decrease smoothing:
self.smoothing_factor = 0.80  # Lower for faster response
```

### **If Calibration Feels Off:**
```python
# In calibration.py, adjust margin:
margin_x = 0.08  # Increase for wider range (was 0.05)
margin_y = 0.08
```

### **If Blinks Not Detected During Calibration:**
```python
# In blink_detector.py, lower threshold temporarily:
self.ear_threshold = 0.18  # More sensitive (was 0.20)
```

---

## ğŸ”¬ Advanced Features

### **Saving/Loading Calibration**

The calibration data can be saved to avoid recalibrating every session:

```python
# Save calibration
import json

calibration_data = calibrator.get_calibration_data()
with open('calibration.json', 'w') as f:
    json.dump(calibration_data, f)

# Load calibration
with open('calibration.json', 'r') as f:
    calibration_data = json.load(f)

calibrator.load_calibration(calibration_data)
mouse_controller.load_calibration(calibration_data)
```

### **Multi-User Support**

Different users have different eye characteristics:

```python
# Save per-user calibration
user_id = "john_doe"
with open(f'calibration_{user_id}.json', 'w') as f:
    json.dump(calibration_data, f)

# Load user-specific calibration
with open(f'calibration_{user_id}.json', 'r') as f:
    calibration_data = json.load(f)
```

---

## ğŸ¯ Use Cases - Now Enhanced

### **Original Use Cases:**
- âœ“ Users with ALS (now without head movement)
- âœ“ Paralysis patients (fully functional with eyes only)
- âœ“ Hands-free computing (more precise control)

### **New Capabilities:**
- âœ… **Quadriplegic users** (no head/hand movement needed)
- âœ… **Locked-in syndrome** (eyes-only communication)
- âœ… **Precision tasks** (accurate pointing for writing/drawing)
- âœ… **Long-duration use** (no neck/shoulder fatigue)
- âœ… **Wheelchair users** (works regardless of position)

---

## ğŸ“Š Data Flow - Updated

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Video Frame
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EyeTracker (MediaPipe)            â”‚
â”‚  â€¢ Detect 478 facial landmarks      â”‚
â”‚  â€¢ Extract iris position            â”‚
â”‚  â€¢ Get eye socket boundaries        â”‚
â”‚  â€¢ Calculate RELATIVE position:     â”‚
â”‚    gaze_x = (iris_x - inner) / widthâ”‚
â”‚    gaze_y = (iris_y - top) / height â”‚
â”‚  â€¢ Output: (gaze_x, gaze_y) 0.0-1.0 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Gaze Ratio (relative)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GazeCalibrator (IF CALIBRATING)   â”‚
â”‚  â€¢ Show fullscreen targets          â”‚
â”‚  â€¢ Collect gaze samples             â”‚
â”‚  â€¢ Wait for blink confirmation      â”‚
â”‚  â€¢ Calculate min/max bounds         â”‚
â”‚  â€¢ Store calibration data           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Calibration Data
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MouseController (Calibrated)      â”‚
â”‚  â€¢ Load calibration bounds          â”‚
â”‚  â€¢ Map gaze ratio to screen:        â”‚
â”‚    screen = (gaze - min) / (max-min)â”‚
â”‚  â€¢ Apply high smoothing (0.85)      â”‚
â”‚  â€¢ Convert to pixels                â”‚
â”‚  â€¢ Move cursor                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš¨ Important Notes

### **Head Movement:**
- **MUST keep head still** during tracking
- System tracks **eye gaze direction**, not head position
- Moving head will cause cursor drift
- Use headrest or neck support if needed

### **Calibration:**
- **Required before first use**
- Recalibrate if:
  - Camera position changes
  - Lighting changes significantly
  - User position changes
  - Accuracy degrades
- Takes ~2 minutes for full 5-point calibration

### **Smoothing Trade-off:**
- Higher smoothing (0.85-0.90) = **Stable but slower**
- Lower smoothing (0.70-0.80) = **Fast but jittery**
- Default 0.85 is optimized for most users

### **Eye Strain:**
- Take breaks every 15-20 minutes
- Blink frequently (natural blinking is different from click blinking)
- Adjust screen brightness
- Use in well-lit environments

---

## ğŸ› Troubleshooting - Updated

### **Calibration Issues:**

**Problem**: Calibration fails or times out  
**Solution**:
- Ensure good lighting on face
- Remove glasses if causing reflections
- Look directly at targets
- Perform deliberate blinks
- Increase timeout in calibration.py (line 91)

**Problem**: Cursor doesn't reach screen edges  
**Solution**:
- Recalibrate with more extreme eye movements
- Reduce margin in calibration.py:
  ```python
  margin_x = 0.02  # Smaller margin (was 0.05)
  ```

### **Tracking Issues:**

**Problem**: Cursor jumps around  
**Solution**:
- Increase smoothing to 0.90
- Ensure head is completely still
- Check lighting (avoid shadows on face)
- Recalibrate

**Problem**: Cursor moves in wrong direction  
**Solution**:
- Recalibrate (may have captured bad data)
- Check camera is not mirrored in settings
- Verify landmarks are detected correctly

**Problem**: "Not calibrated" error  
**Solution**:
- Click "Calibrate Gaze" before "Start Tracking"
- Ensure calibration completed successfully
- Check calibration_data in mouse_controller

---

## ğŸ“š Code Changes Reference

### **Modified Files:**

1. **eye_tracker.py**
   - `get_eye_position()`: Now returns relative gaze ratios instead of absolute position
   - `_calculate_single_eye_gaze()`: New method for single-eye gaze calculation
   - Uses eye socket boundaries as reference

2. **mouse_controller.py**
   - `__init__()`: Removed sensitivity/dead_zone, added calibration vars, increased smoothing to 0.85
   - `move_cursor()`: Complete rewrite using calibration-based mapping
   - `load_calibration()`: New method to load calibration data
   - `get_calibration_status()`: New method to check if calibrated
   - Removed `set_sensitivity()`

3. **calibration.py** (NEW FILE)
   - `GazeCalibrator`: Main calibration class
   - `start_calibration()`: Full 5-point calibration process
   - `_capture_calibration_point()`: Capture single point with blink confirmation
   - `_calculate_calibration_bounds()`: Compute min/max from samples
   - `get_calibration_data()`: Return calibration dict
   - `load_calibration()`: Load saved calibration

4. **main.py**
   - Added `GazeCalibrator` initialization
   - `calibrate_gaze()`: New method for calibration workflow
   - `start_tracking()`: Now checks calibration status first
   - Updated display text and labels

5. **ui.py**
   - Added `calibrate_callback` parameter
   - New "Calibrate Gaze" button (primary action)
   - `update_calibration_status()`: Show calibration state
   - Updated instructions for gaze tracking
   - Changed window title

---

## ğŸ“ Theory: Head Tracking vs Gaze Tracking

### **Head Tracking (OLD):**
```
User moves head â†’ Camera sees face move â†’ Cursor follows face position
Pros: Easy to implement, no calibration
Cons: Tiring, imprecise, requires head mobility
```

### **Gaze Tracking (NEW):**
```
User moves eyes â†’ System detects pupil position in eye socket â†’ 
Calibration maps to screen â†’ Cursor follows gaze direction
Pros: Precise, no head movement, accessible
Cons: Requires calibration, more complex algorithm
```

### **Why Calibration is Essential:**

Everyone's eyes are different:
- Eye size varies
- Iris-to-corner distance varies
- Range of motion varies
- Camera distance varies

Calibration creates a **personal mapping** from your eye movements to screen positions.

**Without calibration**: Cursor may not reach edges, or be off-center  
**With calibration**: Full screen coverage with accurate pointing

---

## ğŸ”® Future Enhancements

### **Potential Additions:**

1. **Adaptive Smoothing**
   - Auto-adjust based on movement speed
   - Lower smoothing for large movements
   - Higher smoothing for small adjustments

2. **Gaze Zones**
   - Define screen areas with different sensitivities
   - Precision mode for small UI elements
   - Fast mode for large navigation

3. **Predictive Tracking**
   - ML model predicts intended target
   - Reduces cursor hunting
   - Improves click accuracy

4. **Auto-Recalibration**
   - Detect calibration drift
   - Suggest recalibration when needed
   - Background calibration during use

5. **Dwell Click Integration**
   - Combine with gaze tracking
   - Hover for X seconds to click
   - Alternative to blink clicking

---

## âœ… Migration Checklist

If upgrading from head tracking version:

- [ ] Backup old configuration
- [ ] Update all Python files
- [ ] Install new dependencies (if any)
- [ ] Run calibration before first use
- [ ] Test cursor accuracy
- [ ] Adjust smoothing if needed
- [ ] Save calibration data
- [ ] Update user documentation
- [ ] Test blink clicking still works
- [ ] Verify error handling

---

## ğŸ“ Support

### **Calibration Not Working?**
1. Check camera permissions
2. Ensure face is well-lit
3. Remove glasses temporarily
4. Try in different lighting
5. Increase timeout in code

### **Cursor Inaccurate?**
1. Recalibrate
2. Ensure head is still
3. Adjust smoothing factor
4. Check for reflections on screen
5. Verify camera is stable

### **Performance Issues?**
1. Close other camera apps
2. Reduce webcam resolution
3. Update graphics drivers
4. Check CPU usage
5. Try lower smoothing

---

## ğŸ† Credits

**Original Concept**: AI Eye-Controlled Mouse (Head Tracking)  
**Major Update**: Gaze Tracking with Calibration (October 2025)  
**Core Technologies**: MediaPipe, OpenCV, PyAutoGUI, NumPy  
**Purpose**: Accessibility for users with limited mobility

---

**This documentation describes the complete gaze tracking system. For basic usage, refer to README.md. For original documentation, see TECHNICAL_DOCUMENTATION.md.**

---

*Version: 2.0 - Gaze Tracking Mode*  
*Last Updated: October 25, 2025*
